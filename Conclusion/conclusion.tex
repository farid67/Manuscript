\chapter*[Conclusion and Perspectives]{Conclusion and Perspectives}
\label{cha:Conclusion}
\addcontentsline{toc}{chapter}{\nameref{cha:Conclusion}}

\section*{Contributions}
\label{sec:ConclusionContributions}
\addcontentsline{toc}{section}{\nameref{sec:ConclusionContributions}}

The purpose of the thesis was to propose solutions to better use medical images in order to improve the characterization of the liver tumors. We successfully presented results proving the ability of deep learning to accurately delineate the liver and its tumors on dynamic CECT images. Moreover, we presented preliminary results proving the ability of automatically extracted deep multiphase imaging features to predict the histological grade of HCCs.

After describing the potential causes that can lead to the different
types of liver cancer, we motivated our choice to mainly focus on
hepatocellular carcinoma (\ac{hcc}).
%This primary cancer type, which is the most frequent one, was described
%through its origin, the way it is usually diagnosed, classified and
%treated. The different steps transforming healthy hepatic cells to cancerous ones have been described, along with the analysis of the physiological changes often caused by this process.
To better characterize the liver tumors, and especially the HCCs, we have decided to rely on medical images solely, through a quantitative and objective analysis.
Regarding the modality choice, we retained computed tomography
because it currently corresponds, with \ac{mri}, to the most widely used modality  for a non-invasive assessment of the disease.
%CT was chosen over \ac{mri} mainly since it is usually the first choice for less-specialized centers, and because it can be more easily interpreted than \ac{mri}. 
With our medical studies review, we showed that the use of dynamic temporal images is a prerequisite to conduct an imaging based liver cancer study.

%In the present work, we presented the two paradigms allowing the computer
%assisted analysis of medical images, either with engineered features, or
%thanks to deep-learning. One of the key aspects of medical images
%analysis being the segment, we compared the different semantic
%segmentation architectures, and evaluated the benefit brought by
%multiphase images which was most of the time neglected by previously
%existing studies. Then we extracted relevant features from our semantic
%segmentation architecture to tackle the prediction of the histological
%grade. Each step of our research work required imaging databases
%precisely annotated by experts in association with researchers to
%improve their applicability.

In the clinical practice, images are usually analyzed by the experts
with the naked eye, but the technological advancements allowed the
creation of computer assisted diagnosis tools (CADs), where a few number
of imaging features were initially used to differentiate benign and
malignant lesions.
A technology called radiomics has been developed to compute a higher
number of features but it took a long time before this technology was
applied to the liver, especially because of the scarcity of publicly
available datasets. We provided a detailed description of the radiomics pipeline, based on a manual segmentation of the \ac{roi}, followed by the extraction of a high number of engineered quantitative features, thus being called \emph{\ac{hcr}} (Hand-Crafted Radiomics).\\
We presented our review, where a total of 15 \emph{\ac{hcr}} studies
applied on \ac{hcc} patients have been analyzed.
We evaluated them against the radiomics quality score (\emph{RQS})
which has been developed to assess the robustness and the
reproducibility of radiomics studies.
We pointed out the lack of reproducibility of the studies, with a mean
\emph{RQS} of  $8.73 \pm 5.57$  points out of a possible maximum value of 36 points. Several important criteria were found as being ignored by the majority of the studies, such as a prospective design, the use of open-sourced data, the evaluation of the prediction on a validation dataset, or the extraction of features at multiple timepoints.

The emergence of deep learning has changed the way a lot of imaging
related problems are comprehended.
The radiomics field has been also impacted by this novel paradigm, and a new approach called \emph{\ac{dlr}} (Deep-Learning
Radiomics) has been initiated, where one or several steps of the
radiomics pipeline are performed by deep learning algorithms.
We reviewed 8 studies implementing a DLR pipeline to characterize liver tumors, and realized that a key part of the radiomics pipeline lies in the segmentation of the \ac{roi}. This step has been found to suffer from a high inter- and intra-observer variability, thus having consequences for the accuracy of the final radiomics-based prediction. 

We consequently reviewed the different studies using deep learning architectures to perform automatic segmentation of the liver and its tumors. We extracted the common key settings shared by the majority of them, such as the cascaded architecture or the use of fully convolutional networks. However, we realized the lack of studies presenting results obtained from multiphase images, which has been a key element in our work. 

We performed the automatic segmentation of an internal dataset composed
of 104 sparse biphasic liver slices obtained from patients suffering
from \ac{hcc} (images available before the injection of contrast medium:
Non-Enhanced \ac{ct}, and at both arterial and portal venous phases).
Considering how challenging the segmentation of liver tissues is, the
amount of data, and the success of such an architecture, we decided to
train several specialized networks in a cascaded way.\\
When evaluating the performances of each specialized network, we
validated the hypothesis that the use of multiphase information allows a
better accuracy than single phased based networks for each task,
with significant difference obtained for the segmentation of the liver
(mean \ac{dsc} of $ 89.9 \pm 15.6 $ for the multiphase network \emph{vs} $ 89.5 \pm 13.2 $ for the best single phase network, $p = 0.005$) and the active part of the lesions (mean \ac{dsc} of $ 75.5 \pm 17.4 $ \emph{vs} $ 71.6 \pm 20.7 $, $p = 0.001$).\\
Regarding single phase networks, the \emph{\ac{pv}} phase was the one
allowing the most accurate segmentation, with significant difference vs
\emph{\ac{ar}} and \emph{\ac{nect}} for the segmentation of the parenchyma (mean \ac{dsc} of $ 88.7 \pm 15.4 $) , the lesion (mean \ac{dsc} of $ 87.8 \pm 9.7 $), and both the
necrotic (mean \ac{dsc} $ 77.8 \pm 12.4 $) and the active (mean \ac{dsc} of $ 71.6 \pm 20.7 $)
parts of the lesion. \\
We validated the hypothesis that several specialized networks combined
in a cascaded architecture perform better than a single network
addressing all the tasks simultaneously (obtained mean slice-wise \ac{dsc} of $ 90.5 \pm 13.2 $ for the parenchyma, $ 75.8 \pm 15.1 $ for the necrosis and $ 59.6 \pm 22.5 $ for the active part of the tumor when using the cascaded architecture with the liver \ac{gt} mask as input).\\
In a fully automatic manner (without using the liver \ac{gt} mask), we were able to reach promising results (regarding the size of the dataset), with a mean slice-wise \ac{dsc} of $ 78.3 \pm 22.1 $ for the parenchyma, $ 50.6 \pm 24.6 $ for the active tumor and $ 68.1 \pm 23.2 $ for the necrotic part of the tumor.\\
We were also able to automatically compute the necrosis rate of the
tumors, with a mean error of 15.9\% when compared with the experts
obtained rates. This prediction is accurate enough to consider the
predicted necrosis rate when evaluating the treatment outcomes. \\
With a robust registration algorithm and an updated version of our cascaded architecture (where specialized networks are trained on a sufficient amount of data using both the LITS\_dB and the G\_dB datasets), we were
able to perform the semantic segmentation of liver and its tumors on
unseen cases.
We validated this assumption by performing the segmentation of TCIA
tumors, and obtained a mean patient-wise \ac{dsc} of $ 73.2 \pm 20.6 $.

We implemented both a HCR and a DLR based pipeline to predict the histological grade of the TCIA patients. Both were trained in a CV manner so that each patient is present once in the testing set. The HCR pipeline consisted in a LASSO logistic regression model responsible for the selection of the relevant features and performing the prediction of the grade of the test patients. The best results were obtained after computation of radiomics features on the original and the filtered images (using LoG). We found that the most relevant features were those affected by the presence of zones with low intensity such as the necrotic areas. Combining multiphase volumes is somehow difficult when using an HCR based pipeline, indeed, features computed from the ``perfusion'' volume and stacked single-phase features did not allow a better prediction accuracy. No significance differences could be observed between results obtained when computing features from the expert defined tumor ROI and those obtained when extracting features from the automatically segmented tumor ROI. This suggested that our deep semantic segmentation cascaded architecture retains the relevant imaging features to perform the wanted task.\\
We then implemented a DLR based architecture to predict the histological grade automatically and provide a prediction at a finer scale.
We proved that features learned by our multiphase semantic segmentation network are relevant to perform this task.
We predicted the grade for central tumor slices, and after a CV
training, we correctly predicted 74\% of them. When considering the
patient histological grade as being the most frequent one in the central
tumor slices, we were able to correctly classify 15 patients over the 18
of the dataset. Regarding the small number of patients involved in the study, it is impossible to determine which one of the implemented paradigms (HCR vs DLR) has the best predictive abilities. It is also worth noting that the results that we presented are only preliminary and further studies are required to confirm them.

As a conclusion, our research work is the first to propose a fully
automatic \emph{\ac{dlr}} pipeline with multiphase images as input. Our
strategy is dedicated to small databases where the entire annotations
are often not available but the same workflow can be applied for larger
datasets. Our \emph{\ac{dlr}} architecture was dedicated, in this research work, to the prediction of the histological grade of \ac{hcc} patients, but our strategy can be extended to other characteristics of \ac{hcc} or other types of liver cancers.

Regarding the lack of publicly available datasets, we encourage the
creation of an open 3D \ac{cect} dataset containing liver volumes of both
healthy and diseased patients with precise and complete pathological
information, and expert delineations of liver, hepatic vessels and
lesions for each phase.


\section*{Perspectives}
\label{sec:Perspectives}
\addcontentsline{toc}{section}{\nameref{sec:Perspectives}}

Several axes of improvement can be considered regarding our research work.
We will discuss potential improvements to bring to the 
semantic segmentation of liver tumors, before raising issues regarding
the current standards for dynamic \ac{cect} acquisition and their impact to 
future multiphasic \ac{ct}-based radiomics studies.
Finally we present ways to incorporate our work in other \ac{dlr}-liver related 
studies, by encouraging the creation of open and precisely 
annotated \ac{cect} datasets.
%When performing a hand-crafted or a deep radiomics study, we still
%believe that the key part will be the area selection preceding the
%computation of the radiomics features.

\subsection*{Semantic Segmentation}
\label{subsec:SemanticSeg}
\addcontentsline{toc}{subsection}{\nameref{subsec:SemanticSeg}}

As discussed before, the \ac{hcr} paradigm often requires manual experts
segmentations, and several studies already discussed the inter- and
intra-observer variability present among the obtained delineations. This
variability is translated in the quality of the retained features, which
tend not to be robust enough when evaluating the predictive 
strength of the model.\\
The \ac{dlr} paradigm allows one or multiple steps of the radiomics pipeline to be implemented with deep learning approaches. We decided to focus on the segmentation step and performed it automatically thanks to deep neural networks, thus reducing the number of potential biases. The automatic segmentation, as
performed in our research work, however requires a high number of
training cases to offer a realistic delineation of the targeted tissues.\\
In the case of liver tumors, a cascaded architecture stacking a first
network responsible for the segmentation of the liver and a second
dedicated only to detect the tumor within the obtained liver mask is
currently the method allowing to obtain the most accurate results.
State-of-the-art liver segmentation methods currently allow us to reach
annotations similar to those obtained by the experts with mean \ac{dsc} often
above 0.95-0.96. We believe that there is no real need to improve the
liver segmentation in the future, and that more interest needs to be
shown in tumor and other liver tissues segmentation.

Regarding the segmentation of liver tumors, current state-of-the-art
results were obtained thanks to post-processing steps such as false
positives (\ac{fp}) filtering method to reduce the number of
objects misclassified as lesions.
It might be that current semantic segmentation architectures still lack the
ability to discriminate between real lesions and other areas of the liver sharing the
same textural properties such as regions close to the vessels as
illustrated in the figure \ref{fig:image5}.



\begin{figure}[th!]
\centering
\includegraphics[width=0.5\linewidth]{../Perspectives/images/chlebus}
\caption{Tumor candidates marked with a dashed white line were classified as false positives, as described by \textbf{Chelbus et al. \cite{Chlebus2018}}.}
\label{fig:image5}
\end{figure}

This low recall might be explained by the poor quality of the
currently available segmentation datasets. Liver annotations often
contain non-hepatic areas (such as air most of the time) or
imperfections close to the organ borders.
When performing the automatic liver segmentation, the deep neural
networks will most of the time be able to avoid these regions. However,
in case they are integrated in the liver mask, they will often be
misclassified as tumors by the second network in the cascade
(responsible for the tumor segmentation).

To overcome this issue, publicly available datasets such as the
\lmttfont{LIST-dB} need to be properly resegmented. They usually only contain
annotations for the parenchyma and/or the tumors, but a third class (or
more) could be incorporated, in order to consider tissues belonging to none of
these groups such as the cysts or the blood vessels.\\
As explained in the section  \ref{section:StateOfTheArtDlImplementations}, current state-of-the-art tumor
segmentation results are often obtained with 2D or 2.5D networks, but
the post-processings steps usually help to improve the obtained accuracy
(via 3D CRF or even simple morphological operations). Several studies
implemented a U-Net like architecture, where the information is
compressed before being decoded to obtain the final segmentation map.
One of the key concepts in these architectures is the propagation of
features learned in the earlier layers later in the network, either
thanks to skip-connections, residual units or even densely connected
layers. Another way to perform the segmentation could be by implementing a
multi-scale pyramidal architecture where tumor-related features can be
learned directly from the raw images at multiple scales instead of being
learned from previously computed features, which is often the case in
the aforementioned architectures.\\
It might also be interesting to perform the segmentation with a full 3D
architecture. Some studies already investigated this solution \cite{Dou2016}, 
but they could not yet outperform state-of-the-art results. \\
Some other concepts could be incorporated in future architectures. Jin et
al. \cite{Jin2018} for example proposed a network that integrated both U-Net and
attention residual mechanism to carry out the segmentation of both the
liver and the lesions. The residual attention mechanism has been
introduced in 2017 by Wang et al. \cite{Wang2017} to perform image
classification, with the idea that the attention mechanism can help the
network focusing on specific parts of the image. The study from Jin et
al. was the first to use the attention mechanism for
semantic segmentation purposes. On the hidden test set of LITS, they
outperformed a lot of 2D-based methods, but were still far from the
top-ranked teams. However, new paradigms such as the self-attention
mechanism, in combination with state-of-the-art 2D and 3D architectures
are certainly an avenue for the improvement of the automatic liver and
tumors segmentation tasks \cite{Chen2019}.

\subsection*{Dynamic contrast-enhanced images}
\label{subsec:DCE}
\addcontentsline{toc}{subsection}{\nameref{subsec:DCE}}

In our research work, the key element is the extraction of features
from dynamic contrast-enhanced images. However, it has been very
difficult to collect dynamic \ac{cect} based images, since only a few
publicly available datasets contain this type of volume. \\
There is a huge room for improvement regarding this specific type of
dataset. It has been mentioned in chapter \ref{liverCancer}, that the
use of images obtained after injection of contrast medium largely
improves the quality of the diagnostic.
Nonetheless, we realized that multiphasic images could be better used in
either the semantic segmentation and/or the radiomics field.\\
The first issue is related to the acquisition protocol required to
obtain this type of images. Most of the time, the different retained
phases, namely arterial, portal venous or delayed phases are acquired
following either visual inspection of the radiologists \footnote{The arterial phase is sometimes acquired
with the help of a bolus tracking technique}, or after a specific
duration following the injection moment that can differ from one study
to the other. Another criteria to consider is the physiological
characteristics of the patient such as its weight that will determine
how the contrast medium is diffused through the liver.

When dealing with multiphase databases, we believe that these key
elements need to be considered, at least at the moment of injection and/or
the duration between the injection and the acquisition.  
%since the weight
%of the patient can be inferred from the liver volume (which can be
%predicted thanks to semantic segmentation).
Currently, only the DICOM
format allows the addition of such metadata (it is only possible to record 
the exact acquisition moment but not the injection moment) 
but they are barely reported and
are often left to default values.\\
Obtaining such data seems really challenging, hence, some techniques
need to be implemented to deal with current multiphase images. 
For example, we believe that a ``phase correction system'', responsible for 
the normalization of images belonging to the same phase, could be
implemented . The automatic detection of the amount of contrast medium still in
the liver could also help to predict the exact duration between the
injection of the contrast medium and the acquisition.

One solution could be to implement an histogram specification algorithm to ``normalize'' images from a given phase. The first step will consist in the computation of a mean histogram per phase (which requires to have a sufficient amount of \ac{ct} images correctly labeled), before transforming the volumes of a given patient to match the obtained mean histogram, as depicted in the figure \ref{fig:specif}.

\begin{figure}[ht!]
\centering
\includegraphics[width=\linewidth]{../Perspectives/images/image_meta}
\caption{Histogram specification experiment conducted to normalize images from the same phase, top row (from left to right): slice before histogram specification, mapping function for the chosen range [-100, 400]; bottom row (from left to right): representation of the mean phase histogram, the current slice histogram and the transformed one after application of histogram specification; slice after histogram specification.}
\label{fig:specif}
\end{figure}

In the case of multiphase images, the expert performing the segmentation
will usually try to obtain only one segmentation volume shared by all the 
registered volumes. This representation might be coherent for the liver mask, 
but we believe that it needs to be modified for internal liver tissues. 
The lesions, for example, will have a different behavior from one phase to the other
(hypo- or hyper-dense tumors for example), consequently, one segmentation per phase should
be performed. This might potentially help the deep neural
networks to better understand the dynamic of the lesions, and also
address the problem of small mis-registration when only one ground truth
segmentation map is shared by all the available phases images.

One long-term objective could be to create, with the help of
radiological experts, a dataset containing registered multiphase \ac{ct}
volumes with expert annotations performed following the aforementioned
protocol.

\subsection*{Deep Radiomics}
\label{subsec:DCR}
\addcontentsline{toc}{subsection}{\nameref{subsec:DCR}}

Regarding our \ac{dlr} study, we believe that the prediction of the
histological grade can be improved. \\
As an example we advocate for a grade prediction at a finer
scale, but it will require to know the exact position of the extracted
sample, or to obtain a map of the heterogeneous regions after surgical
removal of liver tissues through liver resection or liver transplant for
example.\\
In our research work we investigated a patch-wise prediction of the
histological grade but the results were not as promising as those
obtained through our slice-wise approach, especially because our
patch-wise semantic segmentation network needs to be improved.

We are considering the relevant imaging features as being the
ones extracted from the bottleneck part of our U-Net network but other
types of auto-encoders could be investigated to better
extract the relevant information from the raw images, or from the
retained features. We could have also incorporated clinical
data (\ac{afp} (Alpha-FetoProtein) levels, age, \ldots{}) in our pipeline, however such data are
often difficult to retrieve, and challenging to combine with imaging
features, consequently, we decided to focus only on images in the
current work.\\
It is worth also noting that the current registration steps still suffers from limitation
essentially because they were performed using the predicted liver masks as registrations masks. Since, the automatic liver delineation is not perfect, this can result in slightly misregistered volumes. Therefore, we advocate an incorporation of an automatic deep learning based registration step in our \ac{dlr} pipeline, or a workflow requiring no registration at all (for example by considering features learned in each phase separately and combining them for the grade prediction).\\
If more interest is shown in the future towards the prediction of
histological grade, we believe that the existing grading systems have to
be standardized by considering more criteria than just the worst or the
most frequent grade present in the histological slices, which is
currently the case.\\
Our \ac{dlr} architecture obtained promising preliminary results for the prediction of
the histological grade, but we believe that the same architecture can be
adapted to focus on other tasks, such as the prediction of
recurrence after treatment using longitudinal studies.
