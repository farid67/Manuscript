

\chapter{Deep Radiomics for histological grade prediction}

\section{Introduction}\label{introduction}

So far, we proved that semantic segmentation of liver tissues can be
performed using \ac{dl} through robust CV training on both \lmttfont{3DIrcad-dB} and
\lmttfont{TheraHCC-dB}.

We also demonstrated that both a cascaded architecture and the use of
multiphase information allows a better segmentation accuracy than using
single phase images only.

One of the main goals of our research work was to use imaging features
to predict pathological behavior of the disease. The prediction of the
histological grade of the tumor was rarely studied, since only one study
used deep learning tools to perform this task but with MR images as
input \cite{Yang2019}.
Indeed, this task appears to be more challenging than previous \ac{dlr}
liver-related work where either the type of \ac{fll} or the treatment
response (such as the recurrence) were predicted (\textbf{see section \ref{deep-learning-radiomics}}).

\section{Histological HCC grade in the literature
}\label{histological-hcc-grade-in-the-literature}

\subsection{Histological HCC grading
systems}\label{histological-hcc-grading-systems}

Several types of histological grading systems exist, with the most
frequent ones being ES 1954 (Edmonson-Steiner) \cite{EdmondsonHA1954}
and WHO 2010 (World Health Organization) \cite{20113051318}. Differences between these two
grading systems are given in the figure \ref{fig:martins2017_table1}.

\begin{figure}[th!]
\centering
\includegraphics[width=0.9\linewidth]{images/martins2017_table1}
\caption{Features differences between the WHO and the ES1954 histological grading systems as detailed by Martins et al. \cite{Martins2017} \textbf{©2017 Martins-Filho, Paiva, Azevedo and Alves}}
\label{fig:martins2017_table1}
\end{figure}

Even if ES 1954 is the most widely used grading system, a lot of
divergences in the assessment of the grade can be found in the different
studies reviewed by Martins et al. \cite{Martins2017}.

The organization of the patients in different numbers of tiers (3 or 4)
G1, G2, G3 and potentially G4, and the possible classification into low
or high differentiation level reveals a high variability in the
assessment of the histological grade, as seen in the figure \ref{fig:martins2017_figure2}.
As an example, some studies suggested that G2 is closer to G1 than to G3 \cite{Han2013,Zucman-Rossi2015}, therefore, a classification that separates
both G1 and G2 in one group and G3 (with potentially G4 if available) in
the other can be understood.\\


\begin{figure}[th!]
\centering
\includegraphics[width=0.5\linewidth]{images/martins2017_figure2}
\caption{Distribution of the studies according to the grading reference, number of tiers, and data analysis, as detailed by Martins et al. \cite{Martins2017} \textbf{©2017 Martins-Filho, Paiva, Azevedo and Alves}}
\label{fig:martins2017_figure2}
\end{figure}



This difference in the classification of the patients was also noticed
by Han el al. \cite{Han2013} and detailed in the figure \ref{fig:han2013_table3}. They reviewed different articles that used the histological grade to
predict the prognostic of the patients, and realized that no clear
guidelines were given for tumor presenting regions with heterogeneous
grades (two examples of heterogeneous histological \ac{hcc} slices are given in the figure \ref{fig:pawlik_fig4}).

\begin{figure}[th!]
\centering
\includegraphics[width=0.95\linewidth]{images/image9}
\caption{Classification groups used by the studies reviewed by \textbf{©Han et al.} \cite{Han2013}}
\label{fig:han2013_table3}
\end{figure}


\begin{figure}[th!]
\centering
\includegraphics[width=0.7\linewidth]{images/pawlik_fig4}
\caption{Examples of heterogeneous histological slices, as depicted by Pawlik et al. \cite{Pawlik2007} \textbf{©2007 Lippincott Williams \& Wilkins, Inc}}
\label{fig:pawlik_fig4}
\end{figure}


The two possible solutions were to consider the worst grade (as
recommended by the ES grading system), or to consider the most present
one (recommended by the WHO grading system), however clear explanations
of the decision taken in such cases are often undisclosed in the
different studies.

The question regarding which histological \ac{hcc}s grading system to use
remains open. Moreover, various teams proposed to introduce a more
complete grading system where the different features are classified
separately as suggested by Martins et al. and depicted in the
figure \ref{fig:martins2017_fig5}.

\begin{figure}[th!]
\centering
\includegraphics[width=0.9\linewidth]{images/martins2017_fig5}
\caption{New histogical \ac{hcc} grading system proposed by \textbf{©Martins et al. \cite{Martins2017}}}
\label{fig:martins2017_fig5}
\end{figure}


It is common to differentiate between the \emph{clinical} and the
\emph{pathological} grade, where the \emph{clinical} one corresponds to the assessment
performed preoperatively, and the \emph{pathological}\footnote{Important to distinguish from the pathological stage which mainly corresponds to the TNM.} one corresponds to the evaluation
of the sample collected during the surgery.

Some studies even suggested that the preoperative histological grade is
not accurate enough to be used as a prognostic factor, and that because
of the high difference between the NCB (needle core biopsy) grade and the
one obtained from the final surgical specimen (resulted from the
analysis of samples collected during surgery). Pawlik et al.
exposed the concordance in estimating both the clinical and the pathological grades, their results were detailed in the figure \ref{fig:pawlik_table3}.

\begin{figure}[th!]
\centering
\includegraphics[width=0.7\linewidth]{images/pawlik_table3}
\caption{Concordance of pathological and clinical tumor grade estimation, as detailed by Pawlik et al. \textbf{© 2007 Lippincott Williams \& Wilkins, Inc. \cite{Pawlik2007}}}
\label{fig:pawlik_table3}
\end{figure}


As a conclusion, the problem regarding the histological classification
of \ac{hcc} remains open. Two standards are widely used, namely the ES one
from 1954 and the WHO from 2010. They both initially contain 4 groups,
but differ in the features to consider and the way heterogeneous lesions
are supposed to be classified. When different grades are encountered in
the lesion specimen, ES 1954 recommends to consider the worst one,
whereas WHO 2010 advices to consider the most frequent one. New
grading systems were introduced lately in order to overcome these
specific problems.

We will now focus on the only study in the literature that tackled the
problem of predicting the histological grade of \ac{hcc}s through a \ac{dl}
architecture with medical images, before presenting our own automatic \ac{dl}
pipeline.

\subsection{\ac{dlr} based study to predict the histological HCC
grade}\label{dlr-based-study-to-predict-the-histological-hcc-grade}

To our knowledge, only one study tackled the problem of estimating the
histological grade of \ac{hcc}s using a \ac{dl} architecture, but with MR images
as input \cite{Yang2019}.

Yang et al. incorporated 42 patients suffering from \ac{hcc} in their study,
resulting in a total of 51 \ac{hcc}s. Each lesion was analyzed by 2
experienced pathologists who estimated their histological grade after
microscopic examination (the lesions were classified as well, moderately
and poorly differentiated, following the WHO classification system \cite{20113051318}) .
The extracted tissues were obtained through either biopsy (12 patients)
or after surgical removal (2 liver transplants and 28 liver resection).
All the 42 patients underwent pre-operative multiphasic MR imaging
examinations and images were available at 5 different phases
(precontrast, late arterial, portal venous, equilibrium and delayed
phases). They obtained a dataset composed of 9 well, 7 poorly and 35 moderately
differentiated \ac{hcc}s.

For each patient, a \ac{roi} was placed by one expert at the maximal axial
cross-sectional area to entirely cover the tumor. The \ac{roi} was
copied in the 2 slices above and below the chosen one, to obtain a 3D
volume. Intensities of each volume were normalized and 4D tensors were
created for each patient so that each tensor had a $ 32\times32\times5\times5 $ shape
($ 32\times32 $ corresponding to the resampled axial \ac{roi} dimension, the third
dimension being the number of retained slices, and the last dimension being the
dynamic temporal evolution of the \ac{roi} with the 5 phases).

The used architecture is depicted in the figure \ref{fig:Yang2019_Figure2_MCF-3DCNN}. It first splits the 4D
tensors into 5 3D objects so that each slice is treated separately. Each
3D volume was then processed by 2 convolutional, 2 max pooling and 1
fully connected layer. The features of each slice were then
concatenated, before a second fully connected layer followed by a dense
layer with a softmax activation function outputs the probability of
belonging to each one of the three classes (well, moderately or poorly differentiated).

\begin{figure}[th!]
\centering
\includegraphics[width=0.7\linewidth]{images/Yang2019_Fig2}
\caption{MCF-3DCNN architecture as detailed by \textbf{©Yang et al. \cite{Yang2019}}}
\label{fig:Yang2019_Figure2_MCF-3DCNN}
\end{figure}


During the training process, they implemented a label-shuffling method
to overcome the problem of imbalanced data. Furthermore, to avoid the
effect of overfitting, they trained their network with augmented data
(original images were transposed, rotated, and flipped), a learning rate
reduction and the addition of dropout (rate = 0.5).

Using their architecture they were able to correctly classify the \ac{hcc}s
into the 3 differentiation groups with a mean accuracy of \textbf{74\%}.


Their study however suffers from a lot of limitations such as the
reduced size of the cohort, the imbalanced data and the fact that the
analysis was only performed in a manually drawn \ac{voi}.

We have decided to tackle the same issue, but we implemented a fully
automatic pipeline where both the segmentation and the grade prediction
steps were performed by \ac{dl} networks.

\section{Experimental workflow}\label{experimental-workflow}

\lmttfont{TCIA-dB} is the only open dataset where both tomographic images and
histological grade ground truth are available. It originally only
contained raw images without annotations, so an expert performed the
delineations for both the tumor and the necrosis areas on \ac{pv} images only.

In order to perform the prediction of the histological grade, our idea
is to use the imaging features retained for the liver tissue
segmentation, especially those used to segment tumoral structures.

We believe that one easy way to extract relevant imaging features is to
use those retained by the semantic segmentation networks, thus the
better the accuracy regarding the semantic segmentation of the liver
tissues, the more accurate the histological grade prediction will be.

As explained previously, we proved that a cascaded architecture combined
with the use of temporal contrast enhanced images allows a better
delineation of liver tissues. It has been proven that using temporal information can improve the accuracy of the grade prediction, by exploiting the wash-in
wash-out specific features \cite{Okamoto2012}.

To conduct our \ac{dlr} study, we first performed a multiphasic
semantic segmentation of the \lmttfont{TCIA-dB}, before predicting the
histological grade.

To achieve a multiphasic semantic segmentation of the liver tissues we
have to ensure that both the liver and its internal structures such as
the potential tumors are located at the same spatial position between
the different \ac{cect} volumes.


\subsection{Registration}\label{registration}

\begin{figure}[th!]
\centering
\includegraphics[width=0.7\linewidth]{images/RegistrationTCIA_pipeline_vertical2}
\caption{Illustration of the registration pipeline applied to the images of \lmttfont{TCIA-dB}. The first green arrows correspond to the liver segmentation using a network trained on the \lmttfont{LITS-dB}. Dashed blue arrows correspond to the ANTs registration pipeline, where a dilated version of the predicted liver annotations maps are used as registration masks. The ANTs algorithm implements 3 transformations: a rigid, an affine, and a diffeomorphic Syn transformation that computes a deformation grid \cite{Avants2008}. The 3 steps of the ANTs algorithm allows us to obtain registered multiphase images.}
\label{fig:RegistrationTCIA_pipeline_vertical2}
\end{figure}




One way to perform a registration is to implement a series of
transformations (rigid or non-rigid) that will match a moving volume to
a target one. Each step of the registration is controlled by a
similarity loss.
When dealing with \ac{ct} volumes the available losses controlling the
different steps of the registration pipeline can be affected by areas of
the body with a high gradient such as the bones for example. When
registering two \ac{ct} volumes, one can either directly use both the entire
volumes or constraints the registration to a specific area (aka mask).
The liver being a soft organ, it easily moves with the respiratory
motions, in order to reduce the effect of the neighboring parts of the
abdomen, we have decided to restrict the computation of the similarity
metrics to the dilated liver mask area so that the registration
algorithm mainly focus on the gradient present along its borders.

Consequently, the first step for the \lmttfont{TCIA-dB} registration is to perform a
liver semantic segmentation (green arrows in the figure \ref{fig:RegistrationTCIA_pipeline_vertical2}).

\subsection{Automatic liver
segmentation}\label{tcia-db-unsupervised-liver-segmentation}

In the available datasets (\textcolor{red}{\textbf{ref table}}), only \lmttfont{TheraHCC-dB} and
\lmttfont{LITS-dB} contained expert liver delineation.

\lmttfont{TheraHCC-dB} contains annotations only on sparse slices across the liver,
whereas \lmttfont{LITS-dB} contains full 3D pixel-wise liver annotation but it only
contains monophase images, without any information regarding the
acquisition phase (\ac{ar}, \ac{pv} and potentially DELAY volumes are mixed in the dataset).
Our experiments however showed that a liver segmentation network trained
on sufficiently enough cases is able to perform the semantic
segmentation of both \ac{ar} and \ac{pv} raw images independently.
We trained our network called \pplfont{\ac{cect}-Liver} on the 131 volumes of the
\lmttfont{LITS-dB} using the same hyperparameters as the ones detailed
previously (See \textcolor{red}{\textbf{Semantic segmentation applied to the study of HCC}}). When testing the \pplfont{\ac{cect}-Liver} network on \lmttfont{TheraHCC-dB} we
obtained a mean slice-wise \ac{dsc} of $ 90.4 \pm 17.5 $ on the \ac{pv} images and
$ 86.9 \pm 19.1 $ on the \ac{ar} images. These results, close to those obtained
in our previous work using a CV approach \cite{Ouhmich2019}, proved that \pplfont{\ac{cect}-Liver} can
perform liver segmentation on both \ac{ar} and \ac{pv} unseen images.

The \pplfont{CECT-Liver} network was also able to segment unseen volumes of the
\lmttfont{TCIA-dB} in both \ac{ar} and \ac{pv} phases even when the liver presents a big
lesion, as we can see in the figure \ref{fig:LiverPredTciaDb}.

\begin{figure}[ht!]
\centering
\begin{minipage}{0.45\linewidth}
\includegraphics[width=0.9\linewidth]{./images/TCIA_CECTLiver_prediction_TCGA-DD-A11A_slice42_AR_raw}
\end{minipage}
\hspace{0.3cm}
\begin{minipage}{0.45\linewidth}
\includegraphics[width=0.9\linewidth]{./images/TCIA_CECTLiver_prediction_TCGA-DD-A11A_slice42_AR_green_liver}
\end{minipage}

\vspace{0.8cm}
\begin{minipage}{0.45\linewidth}
\includegraphics[width=0.9\linewidth]{./images/TCIA_CECTLiver_prediction_TCGA-DD-A11A_slice42_raw}
\end{minipage}
\hspace{0.3cm}
\begin{minipage}{0.45\linewidth}
\includegraphics[width=0.9\linewidth]{./images/TCIA_CECTLiver_prediction_TCGA-DD-A11A_slice42_greenLiver}
\end{minipage}
\caption{Example of liver segmentation using the \pplfont{\ac{cect}-Liver} network on \lmttfont{TCIA-dB}
patients (Top row \ac{ar} images, bottom row: \ac{pv} images, left:
Raw images, right : liver segmentation as overlay).}
\label{fig:LiverPredTciaDb}
\end{figure}



Once a robust liver segmentation was obtained, we implemented our
registration pipeline.

We have decided to implement the registration pipeline using ANTs \cite{avants2009advanced}, since it has already been used for liver
CT scans registration \cite{Zhao2019,Zhao2020}.

\subsection{ANTs registration}\label{tcia-db-ants-registration}

The classical ANTs registration pipeline is made of 3 steps. The first
two steps consist of linear transformations, where a rigid
transformation is first applied, followed by an affine transformation.
The last one is generally non-linear. In our pipeline,
we used a Syn (\emph{Standard Symmetric normalisation}) transformation, which
processes a gradient field, determining how each point of the space will
shift \cite{Avants2008}.

The MI (Mutual Information) was used as loss function for the first two
steps because it has the advantage of computing the similarity at a
large scale. Linear rigid and affine transformations tend to roughly bring both volumes
in the same space so we decided not to use a finer similarity metric. For the Syn
transformation, we used the CC (Cross Correlation) as loss function. The CC
has the advantage of looking precisely in a region around each voxel
when computing the similarity between the two volumes.

During the registration process, the liver segmentation was used as
registration mask, and we decided to set the \ac{pv} volume as target (fixed)
volume since it usually presents the finer voxel resolution when
compared to \ac{ar} (or DELAY) volume, and since it contains the original
expert annotations.

\begin{figure}
\fbox{
\parbox{\textwidth}{
\begin{enumerate}
\item We initially resampled the \ac{ar} volume so it has the same resolution as the corresponding \ac{pv} volume.
\item We performed the liver segmentation using \pplfont{\ac{cect}-Liver} on both the \ac{pv} and the resampled \ac{ar} volumes in a slice-wise manner with a classical post-processing consisting in applying a binary opening operation to the mask and conserving the big connected component (see green arrows in the figure \ref{fig:RegistrationTCIA_pipeline_vertical2}). We obtained a liver mask for both the \ac{pv} and the resampled \ac{ar} volumes.
\item We applied the registration using both dilated version of the two masks obtained at the end of the second step as registration masks (as depicted by the dashed blue arrows in the figure \ref{fig:RegistrationTCIA_pipeline_vertical2}) (we dilated the liver mask with a SSE of 5cm when setting the registration mask in order to counter any error in the segmentation process, and to always have both the liver and its border included in the registration mask)
\end{enumerate}}}
\captionof{table}{Registration pipeline} \label{regisPipeline}
\end{figure}

The registration allows us to obtain both a new registered arterial volume, a transformation matrix and a deformation field volume. In the axial plane, the obtained deformation fields tend to present high deformation at both the top and the bottom of the liver (which can be explained anatomically since they are surrounded by the air and will be more subject to deformation than central areas of the liver) whereas central areas of the liver present high deformation close to the border. Examples of obtained deformation fields at the end of the registration pipeline are depicted in the figure \ref{fig:deformationGridExamples}.

\begin{figure}
\centering
\begin{minipage}{0.7\linewidth}
\includegraphics[width=\linewidth]{./images/TCIA_TCGA-DD-A11A_deformation_grid_slice49}
\end{minipage}

\vspace{0.8cm}
\begin{minipage}{0.7\linewidth}
\includegraphics[width=\linewidth]{./images/TCIA_TCGA-DD-A11A_deformation_grid_slice68}
\end{minipage}
\caption{Example of deformation grids obtained after applying the registration pipeline on \lmttfont{TCIA-dB} patients}
\label{fig:deformationGridExamples}
\end{figure}
One way to assess the precision of the registration is to apply the
transformation matrix to the initial resampled \ac{ar} liver mask and to
compute the \ac{dsc} with the target \ac{pv} liver mask. When applying this
evaluation, we obtained a mean patient-wise \ac{dsc} of $ 92.8 \pm 3.8 $ at the
end of the registration step on the \lmttfont{TCIA-dB}, sufficient to consider the
registration as successful when compared with those obtained by state-of-the-art
registration methods applied to the liver \cite{Zhao2019}.

The complete registration pipeline applied to the \lmttfont{TCIA-dB} is detailed in the table \ref{regisPipeline}.

\subsection{Automatic multiphase tumor
segmentation}\label{tcia-db-unsupervised-multiphase-tumor-segmentation}

Once both the \ac{ar} and \ac{pv} volumes of the \lmttfont{TCIA-dB} were registered, and the
liver masks obtained, we built the second step of our cascaded
architecture, dedicated to the multiphasic tumor segmentation. In order
to train such a network, we created a multiphase (arterial and portal
venous) database where the temporal volumes of a given patient are
registered and where segmentations of both the liver and tumor regions
are available.
\lmttfont{TheraHCC-dB} and \lmttfont{G-dB} were the only two datasets containing multiphasic
images (as we can see in the \textcolor{red}{\textbf{dataset table}}, however
\lmttfont{G-dB} initially contained ground truth annotation only for the tumors,
with segmentations performed only on the \ac{ar} phase images.
Since \lmttfont{G-dB} contains more cases than \lmttfont{TheraHCC-dB}, we have decided to
build our multiphasic tumor segmentation network on this dataset.
However in order to train a tumor segmentation network, our cascaded
architecture requires to have the liver segmentation mask as input for
the second step (as depicted in the figure \textcolor{red}{\textbf{ref figure
Cascade CARS}}), therefore we had to obtain the liver segmentation
mask for the patients of the \lmttfont{G-dB}.

\ac{ar} and \ac{pv} volumes of the \lmttfont{G-dB} dataset were initially not registered so
we applied the same registration pipeline as the one used for \lmttfont{TCIA-dB} (see table \ref{regisPipeline}). After application of the procedure to
each patient of \lmttfont{G-dB}, we used the resulting transformation matrix to
transform the \ac{ar} tumor mask to the \ac{pv} space as depicted by the red and green dashed arrows in the figure \ref{fig:GDB_registration_pipeline_vertical}.


\begin{figure}[th!]
\centering
\includegraphics[width=0.9\linewidth]{images/GDB/GDB_registration_pipeline_vertical}
\caption{Illustration of the registration pipeline applied to \lmttfont{G-dB}. A similar approach as the one applied to \lmttfont{TCIA-dB} is performed to obtain the registered multiphase images. A final step is added here to transform both the tumor and the liver masks using the registration transformation matrix (red and green dashed arrows)}
\label{fig:GDB_registration_pipeline_vertical}
\end{figure}

We then fused the liver and the tumor masks to obtain a multiclass
segmentation mask that can fit both the \ac{pv} and the registered \ac{ar} volumes, as depicted in the figure \ref{fig:gDbRegisteredPatient}.

\begin{figure}[ht!]
\centering
\begin{minipage}{0.45\linewidth}

\includegraphics[width=0.9\linewidth]{./images/GDB/GDB_Pat77_slice261_AR_TumorPred}
\end{minipage}
\hspace{0.3cm}
\begin{minipage}{0.45\linewidth}
\includegraphics[width=0.9\linewidth]{./images/GDB/GDB_Pat77_slice261_AR_liverTumorPred}
\end{minipage}

\vspace{0.8cm}
\begin{minipage}{0.45\linewidth}
\includegraphics[width=0.9\linewidth]{./images/GDB/GDB_Pat77_slice261_raw_PV}
\end{minipage}
\hspace{0.3cm}
\begin{minipage}{0.45\linewidth}
\includegraphics[width=0.9\linewidth]{./images/GDB/GDB_Pat77_slice261_PV_liverTumorPred}
\end{minipage}
\caption{Example of a patient from \lmttfont{G-dB}, obtained after enhancing the dataset with our semantic segmentation network and our registration pipeline. Top row: \ac{ar}\_registered volume with original tumor expert segmentation, bottom row: \ac{pv}\_volume, left: original raw volumes, right: segmentation mask overlay where the parenchyma is obtained through our segmentation pipeline and the tumor was initially delineated by an expert then transformed to fit the target volume space.}
\label{fig:gDbRegisteredPatient}
\end{figure}


We were able thanks to our cascaded architecture and a robust liver
segmentation network to provide additional annotations to the volumes present in \lmttfont{G-dB} that
originally contained only experts annotations for the tumor area on \ac{ar} volumes.

Once a complete database where both the liver and the tumor segmentation
masks were available, and where \ac{ar} and \ac{pv} volumes were registered, we
trained a robust multiphase tumor segmentation network.

We trained both a \pplfont{DMP-Tumor} and a \pplfont{MPF-Tumor} segmentation network on the
registered \lmttfont{G-dB} dataset, and evaluated them on \lmttfont{TCIA-dB} which
contained expert tumor annotations. We evaluated both \pplfont{DMP} and \pplfont{MPF}
architectures since no statistical differences were available when
comparing results obtained for the tumor segmentation in our previous
work on \lmttfont{TheraHCC-dB} \cite{Ouhmich2019}.

After training both architectures with
the same parameters, we obtained a mean patient-wise \ac{dsc} of $ 73.2 \pm 20.6 $ with \pplfont{MPF}
architecture versus $ 64.9 \pm 27.2 $ when using the \pplfont{DMP} when evaluating the
models on the \lmttfont{TCIA-dB} patients. An example of prediction on the \lmttfont{TCIA-dB} is
depicted in figure \ref{fig:TCIAMultiphaseTumorPred}.

\begin{figure}
\begin{minipage}{0.3\linewidth}
\includegraphics[width=\linewidth]{./images/image13.png}
\end{minipage}
\hspace{0.1cm}
\begin{minipage}{0.3\linewidth}
\includegraphics[width=\linewidth]{./images/image10.png}
\end{minipage}
\hspace{0.1cm}
\begin{minipage}{0.3\linewidth}
\includegraphics[width=\linewidth]{./images/image7.png}
\end{minipage}
\caption{\textcolor{red}{\textbf{TODO: change the figure to better see the differences}}
Example of an image from the \lmttfont{TCIA-dB}, with the obtained predicted tumor
segmentation using the \pplfont{MPF-Tumor} segmentation network (left: raw,
middle: expert annotation, right: obtained segmentation)}
\label{fig:TCIAMultiphaseTumorPred}
\end{figure}


Those results obtained on an external dataset tend to demonstrate a satisfactory precision
of the tumor segmentation when training a cascaded architecture with a
sufficient number of cases.
We retained the \pplfont{MPF-Tumor} segmentation network since it performed
significantly better than the \pplfont{DMP} one ($ p = 0.02 $ using a Wilcoxon signed
paired rank test on the patient-wise \ac{dsc}).
We confirmed the benefit of the cascaded architecture since these results
were obtained using an architecture where the first network was trained
on \lmttfont{LITS-dB} and the second on \lmttfont{G-dB}. We were also able to use
a monophase network for the first step and a multiphasic network for the
second.
This work proved the ability of deep learning (semantic segmentation
network) combined with image processing (registration) to enhance and
complete weakly annotated databases (both \lmttfont{TCIA-dB} and \lmttfont{G-dB} were
enhanced in the same way).

Finally, we decided to keep only two stages in our cascaded architecture
since the only available dataset with expert necrosis annotation was the
\lmttfont{TheraHCC-dB}, containing only 7 patients. This small amount of cases
combined with the design of \lmttfont{TheraHCC-dB} (only sparse slices are
annotated across the volume) might not be enough to precisely
differentiate between the active and the necrotic part of the lesions on
unseen cases. Moreover, the necrosis segmentation appears to be more
sensitive than the tumor segmentation, especially because the necrosis
requires separate annotations in each phase (in case of \ac{ar} and \ac{pv} volumes) since necrotic tissues will respond differently to the evolution of contrast medium.

\subsection{Prediction of the histological grade}\label{prediction-of-the-histological-grade-on-tcia-db}

After obtaining the final cascaded architecture, we built our network dedicated to the
histological grade prediction.

\lmttfont{TCIA-dB} contains images from 18 patients, where 9 were diagnosed with a
grade 3 (G3), 7 with a grade 2 (G2) and 2 with a grade 1 (G1). In order
to obtain a balanced training dataset, it has been decided to split them
into two groups, the first containing G1 and G2 patients, and the second containing G3 patients, as it has been done previously in the literature since G2
was considered as being closer to G1 than to G3 \cite{Han2013,Zucman-Rossi2015}. Patients from the first group (G1 and G2) were considered as
having a low grade (LG), whereas those from the second group have a high
grade (HG).
As explained previously, to train a network dedicated to predict the
histological grade, we have decided to focus on what we called the
relevant imaging semantic features.
We therefore extracted the features from the second network of our
cascaded architecture, to focus on the temporal behavior of the tumor.

The retained network (\pplfont{MPF-Tumor} architecture as illustrated in the figure \ref{CARS_MPF_Full_Fig}) is made of 2 classical U-Net networks, where each
one takes either the \ac{ar} or the \ac{pv} image as input. We believe
that the compressed information present in the bottleneck part of the
network can be sufficient to encode the useful information present in the
image (the U-Net will work as an auto-encoder for the semantic information). Therefore, we extracted for each patient of the \lmttfont{TCIA-dB}, this
encoded information in a slice-wise manner, represented by two $ 32\times32\times512 $
features cubes (one per phase in the \pplfont{MPF-Tumor} architecture) per slice
as depicted in the figure \ref{fig:MPF_Features_Selection}.


\begin{figure}[th!]
\centering
\includegraphics[width=0.95\linewidth]{images/MPF_Features_Selection}
\caption{Red and blue areas correspond to the bottleneck part of the U-Net
network where the features extraction is performed. Each image is then
represented as a $ 32\times32\times512 $ features cube.}
\label{fig:MPF_Features_Selection}
\end{figure}


Before applying the extraction of the features, we normalized
the dimension of the different volumes of the dataset, so that each
voxel measures $ 0.68\times0.68 $mm in the axial plane (because it corresponds to
the resolution of the images used to train our semantic segmentation
network), and that the volumes have a 2.5mm z-spacing (corresponding to the
spacing of the majority of the \ac{pv} volumes in \lmttfont{TCIA-dB}).

We finally built an architecture responsible for the grade prediction.
We focused only on the centrally located tumor slices, since the
histological grade corresponds to a measurement of the evolution of the
disease, which tends to have more physiological effects at the center of
the tumor. Centrally located slices will therefore exhibit the highest
grade for a given patient.

Therefore, a slice-wise architecture was built, first because the
features were computed in a slice-wise manner and second because the
histological grade tends to be heterogeneous in the lesion, meaning that
a slice-wise approach allows us to give a finer prediction to find
potential areas with a more advanced disease.


\begin{figure}[th!]
\centering
\includegraphics[width=0.9\linewidth]{images/gradpredictionArchitecture}
\caption{Slice-wise histological grade prediction using both \ac{ar} and \ac{pv} retained semantic imaging features}
\label{fig:gradpredictionArchitecture}
\end{figure}



The architecture depicted in the figure \ref{fig:gradpredictionArchitecture} works as a dimensionality
reduction algorithm, where the first 1D convolutional layers are dedicated to
reduce the number of features initially present ($ 32\times32\times512 $). The
dimensionality reduction step is performed for each phase separately,
before the remaining features are combined (simple addition in the
features space).
A final dense layer takes the remaining features as input and computes
the probability of belonging to each class thanks to a softmax activation
function (LG vs HG).

When training the network, we decided to consider that each
centrally-located tumor slice of a given patient will have a higher
probability of exhibiting the highest grade, which in this case
corresponds to the observed patient-wise grade (ES1954 histological grading system \cite{EdmondsonHA1954}).

Knowing the composition of \lmttfont{TCIA-dB} (9 high grade patients vs 9 low
grade ones), we performed a 9-fold CV training, so that each patient is
at least present once in the testing set, and so that the training and
the test sets contains both the same number of patients per
class (7 patients from each class in the training set and 1 patient from
each class in the testing set).

After testing several combinations for the hyperparameters, we
fixed the number of retained features to 8 as depicted in the
figure \ref{fig:gradpredictionArchitecture} (meaning that after the features dimensionality reduction,
we obtained a $ 32\times32\times8 $ cube per phase), and we considered a 2cm volume
(corresponding to 8 centrally located slices with a 2.5mm spacing) when
training/testing our architecture.

With our CV-training, we were able to correctly predict the patient-wise
histological grade of 15 patients among 18, as detailed in the table \ref{tab:confusion_matrix} (a patient is considered as being correctly predicted
when at least half of the retained slices were annotated with the
correct \ac{gt} class).
When considering a slice-wise prediction, we were able to correctly
predict \textbf{\textasciitilde{}74\%} of the slices.
\renewcommand{\arraystretch}{2}
\begin{table}[!htp]\centering
\caption{Confusion matrix regarding the patient-wise  histological grade prediction}\label{tab:confusion_matrix}
\begin{tabular}{l|l|c|c|c}
\multicolumn{2}{c}{}&\multicolumn{2}{c}{\textbf{True grade}}&\\
\cline{3-4}
\multicolumn{2}{c|}{}&LG&HG&\multicolumn{1}{c}{\textit{Total}}\\
\cline{2-4}
\multirow{2}{*}{\textbf{Predicted grade}}& LG & 7 & 1 & 8\\
\cline{2-4}
& HG & 2 & 8 & 10 \\
\cline{2-4}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{\textit{Total}} & \multicolumn{1}{c}{9} & \multicolumn{    1}{c}{9} & \multicolumn{1}{c}{18}\\
\end{tabular}
\end{table}
\renewcommand{\arraystretch}{5}
Those results provided a more detailed prediction than the one
consisting of a single patient-wise classification. Being able to
compute the histological grade locally (here in a slice-wise fashion)
allows us to visually focus on the heterogeneous regions that are
crucial when needing to establish a diagnosis. Our pipeline can also
provide a map of the best biopsy sites that will further be necessary in
the clinical practice to either evaluate the progression of the disease
or its prognosis.

